# Data frames

```{r, include = FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=3.5, fig.align="center")
```

*Data frame* is R's name for tabular data. We generally want each row in a data frame to represent a unit of observation, and each column to contain a different type of information about the units of observation. Tabular data in this form is called ["tidy data"](http://vita.had.co.nz/papers/tidy-data.html).

Today we will be using a collection of modern packages collectively known as the [Tidyverse](https://www.tidyverse.org/). R and its predecessor S have a history dating back to 1976. The Tidyverse fixes some dubious design decisions baked into "base R", including having its own slightly improved form of data frame, which is called a *tibble*. Sticking to the Tidyverse where possible is generally safer, Tidyverse packages are more willing to generate errors rather than ignore problems.


## Setting up

Our first step is to download the files we need and to install the Tidyverse. This is the one step where we ask you to copy and paste some code:

```{r, eval=FALSE}
# Download files for this workshop
download.file(
  "https://monashbioinformaticsplatform.github.io/r-intro-resbazvic2024/r-intro.zip",
  destfile="r-intro.zip")
unzip("r-intro.zip")

# Install Tidyverse
install.packages("tidyverse")
```

If you run into problems installing all of the `tidyverse` you may have more success installing individual packages:

```{r, eval=FALSE}
install.packages(c("dplyr","readr","tidyr","ggplot2"))
```

We need to load the `tidyverse` package in order to use it.

```{r, warning=F, message=F}
library(tidyverse)

# OR
library(dplyr)
library(readr)
library(tidyr)
library(ggplot2)
```

The `tidyverse` package loads various other packages, setting up a modern R environment. In this section we will be using functions from the `dplyr`, `readr` and `tidyr` packages.

R is a language with mini-languages within it that solve specific problem domains. `dplyr` is such a mini-language, a set of "verbs" (functions) that work well together. `dplyr`, with the help of `tidyr` for some more complex operations, provides a way to perform most manipulations on a data frame that you might need.


## Loading data

We will use the `read_csv` function from `readr` to load a data set. (See also `read.csv` in base R.) CSV stands for Comma Separated Values, and is a text format used to store tabular data. The first few lines of the file we are loading are shown below. Conventionally the first line contains column headings.

```
name,region,oecd,g77,lat,long,income2017
Afghanistan,asia,FALSE,TRUE,33,66,low
Albania,europe,FALSE,FALSE,41,20,upper_mid
Algeria,africa,FALSE,TRUE,28,3,upper_mid
Andorra,europe,FALSE,FALSE,42.50779,1.52109,high
Angola,africa,FALSE,TRUE,-12.5,18.5,lower_mid
```

```{r}
geo <- read_csv("r-intro/geo.csv")

geo
```

`read_csv` has guessed the type of data each column holds:

* `<chr>` - character strings
* `<dbl>` - numerical values. Technically these are "doubles", which is a way of storing numbers with 15 digits precision.
* `<lgl>` - logical values, `TRUE` or `FALSE`.

We will also encounter:

* `<int>` - integers, a fancy name for whole numbers.
* `<fct>` - factors, categorical data. We will get to this shortly.


You can also see this data frame referring to itself as "a tibble". This is the Tidyverse's improved form of data frame. Tibbles present themselves more conveniently than base R data frames. Base R data frames don't show the type of each column, and output every row when you try to view them.

:::{.callout-tip}
A data frame can also be created from vectors, with the `tibble` function. (See also `data.frame` in base R.) For example:

```{r}
tibble(foo=c(10,20,30), bar=c("a","b","c"))
```

The argument names become column names in the data frame.
:::

:::{.callout-tip}
The *path* to the file on our server is `"r-intro/geo.csv"`. This says, starting from your working directory, look in the directory `r-intro` for the file `geo.csv`. The steps in the path are separated by `/`. Your working directory is shown at the top of the console pane. The path needed might be different on your own computer, depending where you downloaded the file.

One way to work out the correct path is to find the file in the file browser pane, click on it and select "Import Dataset...".

```{r echo=F,out.width="50%",fig.align="left"}
knitr::include_graphics("figures/import.png")
```
:::

## Exploring

The `View` function gives us a spreadsheet-like view of the data frame.

```
View(geo)
```

`print` with the `n` argument can be used to show more than the first 10 rows on the console.

```{r eval=FALSE}
print(geo, n=200)
```

We can extract details of the data frame with further functions:

```{r}
nrow(geo)
ncol(geo)
colnames(geo)
summary(geo)
```


## Indexing data frames

Data frames can be subset using `[row,column]` syntax.

```{r}
geo[4,2]
```

Note that while this is a single value, it is still wrapped in a data frame. (This is a behaviour specific to Tidyverse data frames.) More on this in a moment.

Columns can be given by name.

```{r}
geo[4,"region"]
```

The column or row may be omitted, thereby retrieving the entire row or column.

```{r}
geo[4,]
geo[,"region"]
```

Multiple rows or columns may be retrieved using a vector.

```{r}
rows_wanted <- c(1,3,5)
geo[rows_wanted,]
```

Vector indexing can also be written on a single line.

```{r}
geo[c(1,3,5),]
geo[1:7,]
```


## Columns are vectors

Ok, so how do we actually get data out of a data frame?

Under the hood, a data frame is a list of column vectors. We can use `$` to retrieve columns. Occasionally it is also useful to use `[[ ]]` to retrieve columns, for example if the column name we want is stored in a variable.

```{r}
head( geo$region )
head( geo[["region"]] )
```

To get the "region" value of the 4th row as above, but unwrapped, we can use:

```{r}
geo$region[4]
```

For example, to plot the longitudes and latitudes we could use:

```{r}
plot(geo$long, geo$lat)
```

:::{.challenge}
### Quiz: reading R code {-}

You encounter some wild R code, and aren't sure what it does. Based on R syntax you've encountered so far, what roles are the different names in this code playing?

```
highest <- geo$name[ head(order(geo$lat, decreasing=TRUE), n=10) ]
```

Find all examples of:

A. The name of a variable to store a value to. \
B. The name of a variable to retrieve the value from. \
C. The name of a column to get from a data frame. \
D. The name of a function to call. \
E. The name of an argument to a function call. \

See [here](answers/answers-reading-r-code.html) for answers.
:::

## Logical indexing

A method of indexing that we haven't discussed yet is logical indexing. Instead of specifying the row number or numbers that we want, we can give a logical vector which is `TRUE` for the rows we want and `FALSE` otherwise. This can also be used with vectors.

We will first do this in a slightly verbose way in order to understand it, then learn a more concise way to do this using the `dplyr` package.

Southern countries have latitude less than zero.

```{r}
is_southern <- geo$lat < 0

head(is_southern)
sum(is_southern)
```

`sum` treats TRUE as 1 and FALSE as 0, so it tells us the number of TRUE elements in the vector.

We can use this logical vector to get the southern countries from `geo`:

```{r}
geo[is_southern,]
```

Comparison operators available are:

* `x == y ` -- "equal to"
* `x != y ` -- "not equal to"
* `x < y  ` -- "less than"
* `x > y  ` -- "greater than"
* `x <= y ` -- "less than or equal to"
* `x >= y ` -- "greater than or equal to"

More complicated conditions can be constructed using logical operators:

* `a & b ` -- "and", TRUE only if both `a` and `b` are TRUE.
* `a | b ` -- "or", TRUE if either `a` or `b` or both are TRUE.
* `! a   ` -- "not" , TRUE if `a` is FALSE, and FALSE if `a` is TRUE.

The `oecd` column of `geo` tells which countries are in the Organisation for Economic Co-operation and Development, and the `g77` column tells which countries are in the Group of 77 (an alliance of developing nations). We could see which OECD countries are in the southern hemisphere with:

```{r}
southern_oecd <- is_southern & geo$oecd

geo[southern_oecd,]
```

`is_southern` seems like it should be kept within our `geo` data frame for future use. We can add it as a new column of the data frame with:

```{r}
geo$southern <- is_southern

geo
```

:::{.challenge}
### Challenge: logical indexing {-}


1. Which country is in both the OECD and the G77?

2. Which countries are in neither the OECD nor the G77?

2. Which countries are in the Americas? These have longitudes between -150 and -40. 
:::

### A `dplyr` shorthand

The above method is a little laborious. We have to keep mentioning the name of the data frame, and there is a lot of punctuation to keep track of. `dplyr` provides a slightly magical function called `filter` which lets us write more concisely. For example:

```{r}
filter(geo, lat < 0 & oecd)
```

In the second argument, we are able to refer to columns of the data frame as though they were variables. The code is beautiful, but also opaque. It's important to understand that under the hood we are creating and combining logical vectors.



## Factors

The `count` function from `dplyr` can help us understand the contents of some of the columns in `geo`. `count` is also *magical*, we can refer to columns of the data frame directly in the arguments to `count`.

```{r}
count(geo, region)
count(geo, income2017)
```

One annoyance here is that the different categories in `income2017` aren't in a sensible order. This comes up quite often, for example when sorting or plotting categorical data. R's solution is a further type of vector called a *factor* (think a factor of an experimental design). A factor holds categorical data, and has an associated ordered set of *levels*. It is otherwise quite similar to a character vector.

Any sort of vector can be converted to a factor using the `factor` function. This function defaults to placing the levels in alphabetical order, but takes a `levels` argument that can override this.

```{r}
head( factor(geo$income2017, levels=c("low","lower_mid","upper_mid","high")) )
```

We should modify the `income2017` column of the `geo` table in order to use this:

```{r}
geo$income2017 <- factor(geo$income2017, levels=c("low","lower_mid","upper_mid","high"))
```

`count` now produces the desired order of output:

```{r}
count(geo, income2017)
```

When `plot` is given a factor, it shows a bar plot:

```{r}
plot(geo$income2017)
```

When given two factors, it shows a mosaic plot:

```{r}
plot(geo$income2017, factor(geo$oecd))
```

Similarly we can count two categorical columns at once.

```{r}
count(geo, income2017, oecd)
```

## Readability vs tidyness

The counts we obtained counting `income2017` vs `oecd` were properly tidy in the sense of containing a single unit of observation per row. However to view the data, it would be more convenient to have income as columns and OECD membership as rows. We can use the `pivot_wider` function from `tidyr` to achieve this. (This is also sometimes also called a "cast" or a "spread".)

```{r}
counts <- count(geo, income2017, oecd)
pivot_wider(counts, names_from=income2017, values_from=n)
```

We could further specify `values_fill=list(n=0)` to fill in the `NA` values with 0. Or when using `count`, make sure all the relevant columns are factors and specify `.drop=FALSE`.

:::{.callout-tip}
Tidying is often the first step when exploring a data-set. The [tidyr](http://tidyr.tidyverse.org/) package contains a number of useful functions that help tidy (or un-tidy!) data. We've just seen `pivot_wider` which spreads two columns into multiple columns. The inverse of `pivot_wider` is `pivot_longer`, which gathers multiple columns into two columns: a column of column names, and a column of values. `pivot_longer` is often the first step when tidying a dataset you have received from the wild. (This is sometimes also called a "melt" or a "gather".) 

[Here's an animation illustrating these functions.](https://www.garrickadenbuie.com/project/tidyexplain/#pivot-wider-and-longer)
:::

<!--
:::{.challenge}
### Challenge: counting {-}

Investigate how many OECD and non-OECD nations come from the northern and southern hemispheres.

1. Using `count`.
2. By making a mosaic plot.

Remember you may need to convert columns to factors for `plot` to work, and that a `southern` column could be added to `geo` with:

```{r}
geo$southern <- geo$lat < 0
```
:::
-->

## Sorting

Data frames can be sorted using the `arrange` function in `dplyr`.

```{r}
arrange(geo, lat)
```

Numeric columns are sorted in numeric order. Character columns will be sorted in alphabetical order. Factor columns are sorted in order of their levels. The `desc` helper function can be used to sort in descending order.

```{r}
arrange(geo, desc(name))
```


## Joining data frames

Let's move on to a larger data set. This is from the [Gapminder](https://www.gapminder.org) project and contains information about countries over time.

```{r message=F}
gap <- read_csv("r-intro/gap-minder.csv")
gap
```

:::{.challenge}
### Quiz {-}

What does each row represent in this new data frame?
:::

It would be useful to have general information about countries from `geo` available as columns when we use this data frame. `gap` and `geo` share a column called `name` which can be used to match rows from one to the other. 

```{r}
gap_geo <- left_join(gap, geo, by="name")
gap_geo
```

The output contains all ways of pairing up rows by `name`. In this case each row of `geo` pairs up with multiple rows of `gap`.

:::{.callout-tip}
The "left" in "left join" refers to how rows that can't be paired up are handled. `left_join` keeps all rows from the first data frame but not the second. This is a good default when the intent is to attaching some extra information to a data frame. `inner_join` discards all rows that can't be paired up. `full_join` keeps all rows from both data frames. 

[Here are some animations illustrating joins.](https://www.garrickadenbuie.com/project/tidyexplain/#mutating-joins)
:::

## Further reading

We've covered the fundamentals of dplyr and data frames, but there is much more to learn. Notably, we haven't covered the use of the pipe `|>` to chain `dplyr` verbs together (and you may also come across an older version of the pipe symbol `%>%`). The ["R for Data Science" book](https://r4ds.hadley.nz/) is an excellent source to learn more. The Monash Data Fluency ["Programming and Tidy data analysis in R" course](https://monashdatafluency.github.io/r-progtidy/) also covers this. 











